<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Caffe: Class List</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li class="current"><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Class List</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock">Here are the classes, structs, unions and interfaces with brief descriptions:</div><div class="directory">
<div class="levels">[detail level <span onclick="javascript:toggleLevel(1);">1</span><span onclick="javascript:toggleLevel(2);">2</span><span onclick="javascript:toggleLevel(3);">3</span><span onclick="javascript:toggleLevel(4);">4</span>]</div><table class="directory">
<tr id="row_0_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_0_" class="arrow" onclick="toggleFolder('0_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacecaffe.html" target="_self">caffe</a></td><td class="desc">A layer factory that allows one to register layers. During runtime, registered layers can be called by passing a LayerParameter protobuffer to the CreateLayer function: </td></tr>
<tr id="row_0_0_" style="display:none;"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_0_" class="arrow" onclick="toggleFolder('0_0_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><b>db</b></td><td class="desc"></td></tr>
<tr id="row_0_0_0_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1db_1_1Cursor.html" target="_self">Cursor</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1db_1_1DB.html" target="_self">DB</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1db_1_1Transaction.html" target="_self">Transaction</a></td><td class="desc"></td></tr>
<tr id="row_0_1_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1AbsValLayer.html" target="_self">AbsValLayer</a></td><td class="desc">Computes <img class="formulaInl" alt="$ y = |x| $" src="form_9.png"/> </td></tr>
<tr id="row_0_2_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1AccuracyLayer.html" target="_self">AccuracyLayer</a></td><td class="desc">Computes the classification accuracy for a one-of-many classification task </td></tr>
<tr id="row_0_3_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1AdaDeltaSolver.html" target="_self">AdaDeltaSolver</a></td><td class="desc"></td></tr>
<tr id="row_0_4_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1AdaGradSolver.html" target="_self">AdaGradSolver</a></td><td class="desc"></td></tr>
<tr id="row_0_5_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1AdamSolver.html" target="_self">AdamSolver</a></td><td class="desc"><a class="el" href="classcaffe_1_1AdamSolver.html" title="AdamSolver, an algorithm for first-order gradient-based optimization of stochastic objective function...">AdamSolver</a>, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. Described in [1] </td></tr>
<tr id="row_0_6_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ArgMaxLayer.html" target="_self">ArgMaxLayer</a></td><td class="desc">Compute the index of the <img class="formulaInl" alt="$ K $" src="form_25.png"/> max values for each datum across all dimensions <img class="formulaInl" alt="$ (C \times H \times W) $" src="form_29.png"/> </td></tr>
<tr id="row_0_7_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BaseConvolutionLayer.html" target="_self">BaseConvolutionLayer</a></td><td class="desc">Abstract base class that factors out the BLAS code common to <a class="el" href="classcaffe_1_1ConvolutionLayer.html" title="Convolves the input image with a bank of learned filters, and (optionally) adds biases. ">ConvolutionLayer</a> and <a class="el" href="classcaffe_1_1DeconvolutionLayer.html" title="Convolve the input with a bank of learned filters, and (optionally) add biases, treating filters and ...">DeconvolutionLayer</a> </td></tr>
<tr id="row_0_8_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BaseDataLayer.html" target="_self">BaseDataLayer</a></td><td class="desc">Provides base for data layers that feed blobs to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> </td></tr>
<tr id="row_0_9_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BasePrefetchingDataLayer.html" target="_self">BasePrefetchingDataLayer</a></td><td class="desc"></td></tr>
<tr id="row_0_10_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Batch.html" target="_self">Batch</a></td><td class="desc"></td></tr>
<tr id="row_0_11_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BatchNormLayer.html" target="_self">BatchNormLayer</a></td><td class="desc">Normalizes the input to have 0-mean and/or unit (1) variance across the batch </td></tr>
<tr id="row_0_12_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BatchReindexLayer.html" target="_self">BatchReindexLayer</a></td><td class="desc">Index into the input blob along its first axis </td></tr>
<tr id="row_0_13_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BiasLayer.html" target="_self">BiasLayer</a></td><td class="desc">Computes a sum of two input Blobs, with the shape of the latter <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> "broadcast" to match the shape of the former. Equivalent to tiling the latter <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>, then computing the elementwise sum </td></tr>
<tr id="row_0_14_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BilinearFiller.html" target="_self">BilinearFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with coefficients for bilinear interpolation </td></tr>
<tr id="row_0_15_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Blob.html" target="_self">Blob</a></td><td class="desc">A wrapper around <a class="el" href="classcaffe_1_1SyncedMemory.html" title="Manages memory allocation and synchronization between the host (CPU) and device (GPU). ">SyncedMemory</a> holders serving as the basic computational unit through which <a class="el" href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>s, <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>s, and <a class="el" href="classcaffe_1_1Solver.html" title="An interface for classes that perform optimization on Nets. ">Solver</a>s interact </td></tr>
<tr id="row_0_16_" style="display:none;"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_16_" class="arrow" onclick="toggleFolder('0_16_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BlockingQueue.html" target="_self">BlockingQueue</a></td><td class="desc"></td></tr>
<tr id="row_0_16_0_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BlockingQueue_1_1sync.html" target="_self">sync</a></td><td class="desc"></td></tr>
<tr id="row_0_17_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BNLayer.html" target="_self">BNLayer</a></td><td class="desc"><a class="el" href="classcaffe_1_1Batch.html">Batch</a> normalization the input blob along the channel axis while averaging over the spatial axes </td></tr>
<tr id="row_0_18_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1BNLLLayer.html" target="_self">BNLLLayer</a></td><td class="desc">Computes <img class="formulaInl" alt="$ y = x + \log(1 + \exp(-x)) $" src="form_41.png"/> if <img class="formulaInl" alt="$ x &gt; 0 $" src="form_42.png"/>; <img class="formulaInl" alt="$ y = \log(1 + \exp(x)) $" src="form_43.png"/> otherwise </td></tr>
<tr id="row_0_19_" style="display:none;"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_19_" class="arrow" onclick="toggleFolder('0_19_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Caffe.html" target="_self">Caffe</a></td><td class="desc"></td></tr>
<tr id="row_0_19_0_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span id="arr_0_19_0_" class="arrow" onclick="toggleFolder('0_19_0_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Caffe_1_1RNG.html" target="_self">RNG</a></td><td class="desc"></td></tr>
<tr id="row_0_19_0_0_" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Caffe_1_1RNG_1_1Generator.html" target="_self">Generator</a></td><td class="desc"></td></tr>
<tr id="row_0_20_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ConcatLayer.html" target="_self">ConcatLayer</a></td><td class="desc">Takes at least two <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s and concatenates them along either the num or channel dimension, outputting the result </td></tr>
<tr id="row_0_21_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ConstantFiller.html" target="_self">ConstantFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with constant values <img class="formulaInl" alt="$ x = 0 $" src="form_0.png"/> </td></tr>
<tr id="row_0_22_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ContrastiveLossLayer.html" target="_self">ContrastiveLossLayer</a></td><td class="desc">Computes the contrastive loss <img class="formulaInl" alt="$ E = \frac{1}{2N} \sum\limits_{n=1}^N \left(y\right) d^2 + \left(1-y\right) \max \left(margin-d, 0\right)^2 $" src="form_51.png"/> where <img class="formulaInl" alt="$ d = \left| \left| a_n - b_n \right| \right|_2 $" src="form_52.png"/>. This can be used to train siamese networks </td></tr>
<tr id="row_0_23_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ConvolutionLayer.html" target="_self">ConvolutionLayer</a></td><td class="desc">Convolves the input image with a bank of learned filters, and (optionally) adds biases </td></tr>
<tr id="row_0_24_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1CPUTimer.html" target="_self">CPUTimer</a></td><td class="desc"></td></tr>
<tr id="row_0_25_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1CropLayer.html" target="_self">CropLayer</a></td><td class="desc">Takes a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> and crop it, to the shape specified by the second input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>, across all dimensions after the specified axis </td></tr>
<tr id="row_0_26_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1DataLayer.html" target="_self">DataLayer</a></td><td class="desc"></td></tr>
<tr id="row_0_27_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1DataTransformer.html" target="_self">DataTransformer</a></td><td class="desc">Applies common transformations to the input data, such as scaling, mirroring, substracting the image mean.. </td></tr>
<tr id="row_0_28_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1DeconvolutionLayer.html" target="_self">DeconvolutionLayer</a></td><td class="desc">Convolve the input with a bank of learned filters, and (optionally) add biases, treating filters and convolution parameters in the opposite sense as <a class="el" href="classcaffe_1_1ConvolutionLayer.html" title="Convolves the input image with a bank of learned filters, and (optionally) adds biases. ">ConvolutionLayer</a> </td></tr>
<tr id="row_0_29_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1DropoutLayer.html" target="_self">DropoutLayer</a></td><td class="desc">During training only, sets a random portion of <img class="formulaInl" alt="$x$" src="form_64.png"/> to 0, adjusting the rest of the vector magnitude accordingly </td></tr>
<tr id="row_0_30_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1DummyDataLayer.html" target="_self">DummyDataLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> generated by a <a class="el" href="classcaffe_1_1Filler.html" title="Fills a Blob with constant or randomly-generated data. ">Filler</a> </td></tr>
<tr id="row_0_31_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1EltwiseLayer.html" target="_self">EltwiseLayer</a></td><td class="desc">Compute elementwise operations, such as product and sum, along multiple input Blobs </td></tr>
<tr id="row_0_32_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ELULayer.html" target="_self">ELULayer</a></td><td class="desc">Exponential Linear Unit non-linearity <img class="formulaInl" alt="$ y = \left\{ \begin{array}{lr} x &amp; \mathrm{if} \; x &gt; 0 \\ \alpha (\exp(x)-1) &amp; \mathrm{if} \; x \le 0 \end{array} \right. $" src="form_71.png"/> </td></tr>
<tr id="row_0_33_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1EmbedLayer.html" target="_self">EmbedLayer</a></td><td class="desc">A layer for learning "embeddings" of one-hot vector input. Equivalent to an <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> with one-hot vectors as input, but for efficiency the input is the "hot" index of each column itself </td></tr>
<tr id="row_0_34_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1EuclideanLossLayer.html" target="_self">EuclideanLossLayer</a></td><td class="desc">Computes the Euclidean (L2) loss <img class="formulaInl" alt="$ E = \frac{1}{2N} \sum\limits_{n=1}^N \left| \left| \hat{y}_n - y_n \right| \right|_2^2 $" src="form_74.png"/> for real-valued regression tasks </td></tr>
<tr id="row_0_35_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ExpLayer.html" target="_self">ExpLayer</a></td><td class="desc">Computes <img class="formulaInl" alt="$ y = \gamma ^ {\alpha x + \beta} $" src="form_82.png"/>, as specified by the scale <img class="formulaInl" alt="$ \alpha $" src="form_72.png"/>, shift <img class="formulaInl" alt="$ \beta $" src="form_83.png"/>, and base <img class="formulaInl" alt="$ \gamma $" src="form_84.png"/> </td></tr>
<tr id="row_0_36_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Filler.html" target="_self">Filler</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with constant or randomly-generated data </td></tr>
<tr id="row_0_37_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1FilterLayer.html" target="_self">FilterLayer</a></td><td class="desc">Takes two+ Blobs, interprets last <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> as a selector and filter remaining Blobs accordingly with selector data (0 means that the corresponding item has to be filtered, non-zero means that corresponding item needs to stay) </td></tr>
<tr id="row_0_38_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1FlattenLayer.html" target="_self">FlattenLayer</a></td><td class="desc">Reshapes the input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> into flat vectors </td></tr>
<tr id="row_0_39_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1GaussianFiller.html" target="_self">GaussianFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with Gaussian-distributed values <img class="formulaInl" alt="$ x = a $" src="form_2.png"/> </td></tr>
<tr id="row_0_40_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1HDF5DataLayer.html" target="_self">HDF5DataLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> from HDF5 files </td></tr>
<tr id="row_0_41_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1HDF5OutputLayer.html" target="_self">HDF5OutputLayer</a></td><td class="desc">Write blobs to disk as HDF5 files </td></tr>
<tr id="row_0_42_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1HingeLossLayer.html" target="_self">HingeLossLayer</a></td><td class="desc">Computes the hinge loss for a one-of-many classification task </td></tr>
<tr id="row_0_43_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Im2colLayer.html" target="_self">Im2colLayer</a></td><td class="desc">A helper for image operations that rearranges image regions into column vectors. Used by <a class="el" href="classcaffe_1_1ConvolutionLayer.html" title="Convolves the input image with a bank of learned filters, and (optionally) adds biases. ">ConvolutionLayer</a> to perform convolution by matrix multiplication </td></tr>
<tr id="row_0_44_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ImageDataLayer.html" target="_self">ImageDataLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> from image files </td></tr>
<tr id="row_0_45_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1InfogainLossLayer.html" target="_self">InfogainLossLayer</a></td><td class="desc">A generalization of <a class="el" href="classcaffe_1_1SoftmaxWithLossLayer.html" title="Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued pre...">SoftmaxWithLossLayer</a> that takes an "information gain" (infogain) matrix specifying the "value" of all label pairs </td></tr>
<tr id="row_0_46_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1InnerProductLayer.html" target="_self">InnerProductLayer</a></td><td class="desc">Also known as a "fully-connected" layer, computes an inner product with a set of learned weights, and (optionally) adds biases </td></tr>
<tr id="row_0_47_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1InputLayer.html" target="_self">InputLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> by assigning tops directly </td></tr>
<tr id="row_0_48_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1InternalThread.html" target="_self">InternalThread</a></td><td class="desc"></td></tr>
<tr id="row_0_49_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1InterpLayer.html" target="_self">InterpLayer</a></td><td class="desc">Changes the spatial resolution by bi-linear interpolation. The target size is specified in terms of pixels. The start and end pixels of the input are mapped to the start and end pixels of the output </td></tr>
<tr id="row_0_50_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Layer.html" target="_self">Layer</a></td><td class="desc">An interface for the units of computation which can be composed into a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> </td></tr>
<tr id="row_0_51_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LayerRegisterer.html" target="_self">LayerRegisterer</a></td><td class="desc"></td></tr>
<tr id="row_0_52_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LayerRegistry.html" target="_self">LayerRegistry</a></td><td class="desc"></td></tr>
<tr id="row_0_53_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LogLayer.html" target="_self">LogLayer</a></td><td class="desc">Computes <img class="formulaInl" alt="$ y = log_{\gamma}(\alpha x + \beta) $" src="form_109.png"/>, as specified by the scale <img class="formulaInl" alt="$ \alpha $" src="form_72.png"/>, shift <img class="formulaInl" alt="$ \beta $" src="form_83.png"/>, and base <img class="formulaInl" alt="$ \gamma $" src="form_84.png"/> </td></tr>
<tr id="row_0_54_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LossLayer.html" target="_self">LossLayer</a></td><td class="desc">An interface for <a class="el" href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>s that take two <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s as input &ndash; usually (1) predictions and (2) ground-truth labels &ndash; and output a singleton <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> representing the loss </td></tr>
<tr id="row_0_55_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LRNLayer.html" target="_self">LRNLayer</a></td><td class="desc">Normalize the input in a local region across or within feature maps </td></tr>
<tr id="row_0_56_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LSTMLayer.html" target="_self">LSTMLayer</a></td><td class="desc">Processes sequential inputs using a "Long Short-Term Memory" (LSTM) [1] style recurrent neural network (RNN). Implemented by unrolling the LSTM computation through time </td></tr>
<tr id="row_0_57_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1LSTMUnitLayer.html" target="_self">LSTMUnitLayer</a></td><td class="desc">A helper for <a class="el" href="classcaffe_1_1LSTMLayer.html" title="Processes sequential inputs using a &quot;Long Short-Term Memory&quot; (LSTM) [1] style recurrent neural networ...">LSTMLayer</a>: computes a single timestep of the non-linearity of the LSTM, producing the updated cell and hidden states </td></tr>
<tr id="row_0_58_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1MemoryDataLayer.html" target="_self">MemoryDataLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> from memory </td></tr>
<tr id="row_0_59_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1MSRAFiller.html" target="_self">MSRAFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values <img class="formulaInl" alt="$ x \sim N(0, \sigma^2) $" src="form_7.png"/> where <img class="formulaInl" alt="$ \sigma^2 $" src="form_8.png"/> is set inversely proportional to number of incoming nodes, outgoing nodes, or their average </td></tr>
<tr id="row_0_60_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1MultinomialLogisticLossLayer.html" target="_self">MultinomialLogisticLossLayer</a></td><td class="desc">Computes the multinomial logistic loss for a one-of-many classification task, directly taking a predicted probability distribution as input </td></tr>
<tr id="row_0_61_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1MVNLayer.html" target="_self">MVNLayer</a></td><td class="desc">Normalizes the input to have 0-mean and/or unit (1) variance </td></tr>
<tr id="row_0_62_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1NesterovSolver.html" target="_self">NesterovSolver</a></td><td class="desc"></td></tr>
<tr id="row_0_63_" style="display:none;"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_63_" class="arrow" onclick="toggleFolder('0_63_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Net.html" target="_self">Net</a></td><td class="desc">Connects <a class="el" href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>s together into a directed acyclic graph (DAG) specified by a NetParameter </td></tr>
<tr id="row_0_63_0_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Net_1_1Callback.html" target="_self">Callback</a></td><td class="desc"></td></tr>
<tr id="row_0_64_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1NeuronLayer.html" target="_self">NeuronLayer</a></td><td class="desc">An interface for layers that take one blob as input ( <img class="formulaInl" alt="$ x $" src="form_11.png"/>) and produce one equally-sized blob as output ( <img class="formulaInl" alt="$ y $" src="form_13.png"/>), where each element of the output depends only on the corresponding input element </td></tr>
<tr id="row_0_65_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ParameterLayer.html" target="_self">ParameterLayer</a></td><td class="desc"></td></tr>
<tr id="row_0_66_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1PoolingLayer.html" target="_self">PoolingLayer</a></td><td class="desc">Pools the input image by taking the max, average, etc. within regions </td></tr>
<tr id="row_0_67_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1PositiveUnitballFiller.html" target="_self">PositiveUnitballFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values <img class="formulaInl" alt="$ x \in [0, 1] $" src="form_3.png"/> such that <img class="formulaInl" alt="$ \forall i \sum_j x_{ij} = 1 $" src="form_4.png"/> </td></tr>
<tr id="row_0_68_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1PowerLayer.html" target="_self">PowerLayer</a></td><td class="desc">Computes <img class="formulaInl" alt="$ y = (\alpha x + \beta) ^ \gamma $" src="form_128.png"/>, as specified by the scale <img class="formulaInl" alt="$ \alpha $" src="form_72.png"/>, shift <img class="formulaInl" alt="$ \beta $" src="form_83.png"/>, and power <img class="formulaInl" alt="$ \gamma $" src="form_84.png"/> </td></tr>
<tr id="row_0_69_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1PReLULayer.html" target="_self">PReLULayer</a></td><td class="desc">Parameterized Rectified Linear Unit non-linearity <img class="formulaInl" alt="$ y_i = \max(0, x_i) + a_i \min(0, x_i) $" src="form_131.png"/>. The differences from <a class="el" href="classcaffe_1_1ReLULayer.html" title="Rectified Linear Unit non-linearity . The simple max is fast to compute, and the function does not sa...">ReLULayer</a> are 1) negative slopes are learnable though backprop and 2) negative slopes can vary across channels. The number of axes of input blob should be greater than or equal to 2. The 1st axis (0-based) is seen as channels </td></tr>
<tr id="row_0_70_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1PythonLayer.html" target="_self">PythonLayer</a></td><td class="desc"></td></tr>
<tr id="row_0_71_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1RecurrentLayer.html" target="_self">RecurrentLayer</a></td><td class="desc">An abstract class for implementing recurrent behavior inside of an unrolled network. This <a class="el" href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a> type cannot be instantiated &ndash; instead, you should use one of its implementations which defines the recurrent architecture, such as <a class="el" href="classcaffe_1_1RNNLayer.html" title="Processes time-varying inputs using a simple recurrent neural network (RNN). Implemented as a network...">RNNLayer</a> or <a class="el" href="classcaffe_1_1LSTMLayer.html" title="Processes sequential inputs using a &quot;Long Short-Term Memory&quot; (LSTM) [1] style recurrent neural networ...">LSTMLayer</a> </td></tr>
<tr id="row_0_72_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ReductionLayer.html" target="_self">ReductionLayer</a></td><td class="desc">Compute "reductions" &ndash; operations that return a scalar output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> for an input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> of arbitrary size, such as the sum, absolute sum, and sum of squares </td></tr>
<tr id="row_0_73_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ReLULayer.html" target="_self">ReLULayer</a></td><td class="desc">Rectified Linear Unit non-linearity <img class="formulaInl" alt="$ y = \max(0, x) $" src="form_152.png"/>. The simple max is fast to compute, and the function does not saturate </td></tr>
<tr id="row_0_74_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ReshapeLayer.html" target="_self">ReshapeLayer</a></td><td class="desc"></td></tr>
<tr id="row_0_75_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1RMSPropSolver.html" target="_self">RMSPropSolver</a></td><td class="desc"></td></tr>
<tr id="row_0_76_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1RNNLayer.html" target="_self">RNNLayer</a></td><td class="desc">Processes time-varying inputs using a simple recurrent neural network (RNN). Implemented as a network unrolling the RNN computation in time </td></tr>
<tr id="row_0_77_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ScaleLayer.html" target="_self">ScaleLayer</a></td><td class="desc">Computes the elementwise product of two input Blobs, with the shape of the latter <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> "broadcast" to match the shape of the former. Equivalent to tiling the latter <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>, then computing the elementwise product. Note: for efficiency and convenience, this layer can additionally perform a "broadcast" sum too when <code>bias_term: true</code> is set </td></tr>
<tr id="row_0_78_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SGDSolver.html" target="_self">SGDSolver</a></td><td class="desc">Optimizes the parameters of a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> using stochastic gradient descent (SGD) with momentum </td></tr>
<tr id="row_0_79_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html" target="_self">SigmoidCrossEntropyLossLayer</a></td><td class="desc">Computes the cross-entropy (logistic) loss <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_164.png"/>, often used for predicting targets interpreted as probabilities </td></tr>
<tr id="row_0_80_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SigmoidLayer.html" target="_self">SigmoidLayer</a></td><td class="desc">Sigmoid function non-linearity <img class="formulaInl" alt="$ y = (1 + \exp(-x))^{-1} $" src="form_170.png"/>, a classic choice in neural networks </td></tr>
<tr id="row_0_81_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SignalHandler.html" target="_self">SignalHandler</a></td><td class="desc"></td></tr>
<tr id="row_0_82_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SilenceLayer.html" target="_self">SilenceLayer</a></td><td class="desc">Ignores bottom blobs while producing no top blobs. (This is useful to suppress outputs during testing.) </td></tr>
<tr id="row_0_83_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SliceLayer.html" target="_self">SliceLayer</a></td><td class="desc">Takes a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> and slices it along either the num or channel dimension, outputting multiple sliced <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> results </td></tr>
<tr id="row_0_84_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SoftmaxLayer.html" target="_self">SoftmaxLayer</a></td><td class="desc">Computes the softmax function </td></tr>
<tr id="row_0_85_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SoftmaxWithLossLayer.html" target="_self">SoftmaxWithLossLayer</a></td><td class="desc">Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued predictions through a softmax to get a probability distribution over classes </td></tr>
<tr id="row_0_86_" style="display:none;"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_86_" class="arrow" onclick="toggleFolder('0_86_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Solver.html" target="_self">Solver</a></td><td class="desc">An interface for classes that perform optimization on <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>s </td></tr>
<tr id="row_0_86_0_" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Solver_1_1Callback.html" target="_self">Callback</a></td><td class="desc"></td></tr>
<tr id="row_0_87_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SolverRegisterer.html" target="_self">SolverRegisterer</a></td><td class="desc"></td></tr>
<tr id="row_0_88_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SolverRegistry.html" target="_self">SolverRegistry</a></td><td class="desc"></td></tr>
<tr id="row_0_89_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SplitLayer.html" target="_self">SplitLayer</a></td><td class="desc">Creates a "split" path in the network by copying the bottom <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> into multiple top <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s to be used by multiple consuming layers </td></tr>
<tr id="row_0_90_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SPPLayer.html" target="_self">SPPLayer</a></td><td class="desc">Does spatial pyramid pooling on the input image by taking the max, average, etc. within regions so that the result vector of different sized images are of the same size </td></tr>
<tr id="row_0_91_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SwishLayer.html" target="_self">SwishLayer</a></td><td class="desc">Swish non-linearity <img class="formulaInl" alt="$ y = x \sigma (\beta x) $" src="form_172.png"/>. A novel activation function that tends to work better than ReLU [1] </td></tr>
<tr id="row_0_92_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1SyncedMemory.html" target="_self">SyncedMemory</a></td><td class="desc">Manages memory allocation and synchronization between the host (CPU) and device (GPU) </td></tr>
<tr id="row_0_93_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1TanHLayer.html" target="_self">TanHLayer</a></td><td class="desc">TanH hyperbolic tangent non-linearity <img class="formulaInl" alt="$ y = \frac{\exp(2x) - 1}{\exp(2x) + 1} $" src="form_174.png"/>, popular in auto-encoders </td></tr>
<tr id="row_0_94_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1ThresholdLayer.html" target="_self">ThresholdLayer</a></td><td class="desc">Tests whether the input exceeds a threshold: outputs 1 for inputs above threshold; 0 otherwise </td></tr>
<tr id="row_0_95_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1TileLayer.html" target="_self">TileLayer</a></td><td class="desc">Copy a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> along specified dimensions </td></tr>
<tr id="row_0_96_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1Timer.html" target="_self">Timer</a></td><td class="desc"></td></tr>
<tr id="row_0_97_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1UniformFiller.html" target="_self">UniformFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with uniformly distributed values <img class="formulaInl" alt="$ x\sim U(a, b) $" src="form_1.png"/> </td></tr>
<tr id="row_0_98_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1WindowDataLayer.html" target="_self">WindowDataLayer</a></td><td class="desc">Provides data to the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> from windows of images files, specified by a window data file. This layer is <em>DEPRECATED</em> and only kept for archival purposes for use by the original R-CNN </td></tr>
<tr id="row_0_99_" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classcaffe_1_1XavierFiller.html" target="_self">XavierFiller</a></td><td class="desc">Fills a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values <img class="formulaInl" alt="$ x \sim U(-a, +a) $" src="form_5.png"/> where <img class="formulaInl" alt="$ a $" src="form_6.png"/> is set inversely proportional to number of incoming nodes, outgoing nodes, or their average </td></tr>
</table>
</div><!-- directory -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Apr 2 2020 11:05:23 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
