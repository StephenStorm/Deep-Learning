\hypertarget{classcaffe_1_1SwishLayer}{}\section{caffe\+:\+:Swish\+Layer$<$ Dtype $>$ Class Template Reference}
\label{classcaffe_1_1SwishLayer}\index{caffe\+::\+Swish\+Layer$<$ Dtype $>$@{caffe\+::\+Swish\+Layer$<$ Dtype $>$}}


Swish non-\/linearity $ y = x \sigma (\beta x) $. A novel activation function that tends to work better than Re\+LU \mbox{[}1\mbox{]}.  




{\ttfamily \#include $<$swish\+\_\+layer.\+hpp$>$}

Inheritance diagram for caffe\+:\+:Swish\+Layer$<$ Dtype $>$\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=3.000000cm]{classcaffe_1_1SwishLayer}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classcaffe_1_1SwishLayer_afd59cd91314ef60acef0d3ba80500818}{Swish\+Layer} (const Layer\+Parameter \&param)
\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a07ce69f7855f0374ad826fb59fc58712}{Layer\+Set\+Up} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\begin{DoxyCompactList}\small\item\em Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a06173b1a0bdc7df0a21535a1fc0cf2a9}{Reshape} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\begin{DoxyCompactList}\small\item\em Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. \end{DoxyCompactList}\item 
virtual const char $\ast$ \hyperlink{classcaffe_1_1SwishLayer_a8f031a11b307fe5d20d20c172c390b77}{type} () const \hypertarget{classcaffe_1_1SwishLayer_a8f031a11b307fe5d20d20c172c390b77}{}\label{classcaffe_1_1SwishLayer_a8f031a11b307fe5d20d20c172c390b77}

\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a31f958632f52a0cbb86028b99c200e7d}{Forward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a56f6507efe23228a442eeb3aa239e721}{Forward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)\hypertarget{classcaffe_1_1SwishLayer_a56f6507efe23228a442eeb3aa239e721}{}\label{classcaffe_1_1SwishLayer_a56f6507efe23228a442eeb3aa239e721}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the layer output. Fall back to \hyperlink{classcaffe_1_1SwishLayer_a31f958632f52a0cbb86028b99c200e7d}{Forward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a30878255baed3925bb15d7ebf0615316}{Backward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the error gradient w.\+r.\+t. the sigmoid inputs. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1SwishLayer_a3af97f24bcffee3670b339d193ed1ec1}{Backward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)\hypertarget{classcaffe_1_1SwishLayer_a3af97f24bcffee3670b339d193ed1ec1}{}\label{classcaffe_1_1SwishLayer_a3af97f24bcffee3670b339d193ed1ec1}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. Fall back to \hyperlink{classcaffe_1_1SwishLayer_a30878255baed3925bb15d7ebf0615316}{Backward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
shared\+\_\+ptr$<$ \hyperlink{classcaffe_1_1SigmoidLayer}{Sigmoid\+Layer}$<$ Dtype $>$ $>$ \hyperlink{classcaffe_1_1SwishLayer_a6935dac80459c96eccd8916eae8762b4}{sigmoid\+\_\+layer\+\_\+}\hypertarget{classcaffe_1_1SwishLayer_a6935dac80459c96eccd8916eae8762b4}{}\label{classcaffe_1_1SwishLayer_a6935dac80459c96eccd8916eae8762b4}

\begin{DoxyCompactList}\small\item\em The internal \hyperlink{classcaffe_1_1SigmoidLayer}{Sigmoid\+Layer}. \end{DoxyCompactList}\item 
shared\+\_\+ptr$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $>$ \hyperlink{classcaffe_1_1SwishLayer_a6b1063f59cffc8262c89928d04f75224}{sigmoid\+\_\+input\+\_\+}\hypertarget{classcaffe_1_1SwishLayer_a6b1063f59cffc8262c89928d04f75224}{}\label{classcaffe_1_1SwishLayer_a6b1063f59cffc8262c89928d04f75224}

\begin{DoxyCompactList}\small\item\em sigmoid\+\_\+input\+\_\+ stores the input of the \hyperlink{classcaffe_1_1SigmoidLayer}{Sigmoid\+Layer}. \end{DoxyCompactList}\item 
shared\+\_\+ptr$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $>$ \hyperlink{classcaffe_1_1SwishLayer_a5fdfed8eb4ee88f52d460ddd02e728e2}{sigmoid\+\_\+output\+\_\+}\hypertarget{classcaffe_1_1SwishLayer_a5fdfed8eb4ee88f52d460ddd02e728e2}{}\label{classcaffe_1_1SwishLayer_a5fdfed8eb4ee88f52d460ddd02e728e2}

\begin{DoxyCompactList}\small\item\em sigmoid\+\_\+output\+\_\+ stores the output of the \hyperlink{classcaffe_1_1SigmoidLayer}{Sigmoid\+Layer}. \end{DoxyCompactList}\item 
vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \hyperlink{classcaffe_1_1SwishLayer_a8a1e381a418c6ff8653c26e4e9f9704e}{sigmoid\+\_\+bottom\+\_\+vec\+\_\+}\hypertarget{classcaffe_1_1SwishLayer_a8a1e381a418c6ff8653c26e4e9f9704e}{}\label{classcaffe_1_1SwishLayer_a8a1e381a418c6ff8653c26e4e9f9704e}

\begin{DoxyCompactList}\small\item\em bottom vector holder to call the underlying \hyperlink{classcaffe_1_1Layer_aa5fc9ddb31b58958653372bdaaccde94}{Sigmoid\+Layer\+::\+Forward} \end{DoxyCompactList}\item 
vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \hyperlink{classcaffe_1_1SwishLayer_aee0d061e57ece8bf1524caa2a4b3522c}{sigmoid\+\_\+top\+\_\+vec\+\_\+}\hypertarget{classcaffe_1_1SwishLayer_aee0d061e57ece8bf1524caa2a4b3522c}{}\label{classcaffe_1_1SwishLayer_aee0d061e57ece8bf1524caa2a4b3522c}

\begin{DoxyCompactList}\small\item\em top vector holder to call the underlying \hyperlink{classcaffe_1_1Layer_aa5fc9ddb31b58958653372bdaaccde94}{Sigmoid\+Layer\+::\+Forward} \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Dtype$>$\\*
class caffe\+::\+Swish\+Layer$<$ Dtype $>$}

Swish non-\/linearity $ y = x \sigma (\beta x) $. A novel activation function that tends to work better than Re\+LU \mbox{[}1\mbox{]}. 

\mbox{[}1\mbox{]} Prajit Ramachandran, Barret Zoph, Quoc V. Le. \char`\"{}\+Searching for
    Activation Functions\char`\"{}. ar\+Xiv preprint ar\+Xiv\+:1710.\+05941v2 (2017). 

\subsection{Constructor \& Destructor Documentation}
\index{caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}!Swish\+Layer@{Swish\+Layer}}
\index{Swish\+Layer@{Swish\+Layer}!caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}}
\subsubsection[{\texorpdfstring{Swish\+Layer(const Layer\+Parameter \&param)}{SwishLayer(const LayerParameter &param)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ {\bf caffe\+::\+Swish\+Layer}$<$ Dtype $>$\+::{\bf Swish\+Layer} (
\begin{DoxyParamCaption}
\item[{const Layer\+Parameter \&}]{param}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}\hypertarget{classcaffe_1_1SwishLayer_afd59cd91314ef60acef0d3ba80500818}{}\label{classcaffe_1_1SwishLayer_afd59cd91314ef60acef0d3ba80500818}

\begin{DoxyParams}{Parameters}
{\em param} & provides Swish\+Parameter swish\+\_\+param, with \hyperlink{classcaffe_1_1SwishLayer}{Swish\+Layer} options\+:
\begin{DoxyItemize}
\item beta ({\bfseries optional}, default 1). the value $ \beta $ in the $ y = x \sigma (\beta x) $. 
\end{DoxyItemize}\\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\index{caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}}
\subsubsection[{\texorpdfstring{Backward\+\_\+cpu(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom)}{Backward_cpu(const vector< Blob< Dtype > * > &top, const vector< bool > &propagate_down, const vector< Blob< Dtype > * > &bottom)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Swish\+Layer}$<$ Dtype $>$\+::Backward\+\_\+cpu (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top, }
\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1SwishLayer_a30878255baed3925bb15d7ebf0615316}{}\label{classcaffe_1_1SwishLayer_a30878255baed3925bb15d7ebf0615316}


Computes the error gradient w.\+r.\+t. the sigmoid inputs. 


\begin{DoxyParams}{Parameters}
{\em top} & output \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ containing error gradients $ \frac{\partial E}{\partial y} $ with respect to computed outputs $ y $ 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \hyperlink{classcaffe_1_1Layer_a53df1e081767e07bfb4c81657f4acd0a}{Layer\+::\+Backward}. \\
\hline
{\em bottom} & input \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $; Backward fills their diff with gradients $ \frac{\partial E}{\partial x} = \frac{\partial E}{\partial y}(\beta y + \sigma (\beta x)(1 - \beta y)) $ if propagate\+\_\+down\mbox{[}0\mbox{]} 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \hyperlink{classcaffe_1_1Layer_a64d15855f882af4b82e83fa993c4e7c6}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}}
\subsubsection[{\texorpdfstring{Forward\+\_\+cpu(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{Forward_cpu(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Swish\+Layer}$<$ Dtype $>$\+::Forward\+\_\+cpu (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1SwishLayer_a31f958632f52a0cbb86028b99c200e7d}{}\label{classcaffe_1_1SwishLayer_a31f958632f52a0cbb86028b99c200e7d}

\begin{DoxyParams}{Parameters}
{\em bottom} & input \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $ 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the computed outputs $ y = x \sigma (\beta x) $. 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \hyperlink{classcaffe_1_1Layer_add965883f75bbf90c7a06f960cda7a1a}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}!Layer\+Set\+Up@{Layer\+Set\+Up}}
\index{Layer\+Set\+Up@{Layer\+Set\+Up}!caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}}
\subsubsection[{\texorpdfstring{Layer\+Set\+Up(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{LayerSetUp(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Swish\+Layer}$<$ Dtype $>$\+::Layer\+Set\+Up (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}\hypertarget{classcaffe_1_1SwishLayer_a07ce69f7855f0374ad826fb59fc58712}{}\label{classcaffe_1_1SwishLayer_a07ce69f7855f0374ad826fb59fc58712}


Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the preshaped input blobs, whose data fields store the input data for this layer \\
\hline
{\em top} & the allocated but unshaped output blobs\\
\hline
\end{DoxyParams}
This method should do one-\/time layer specific setup. This includes reading and processing relevent parameters from the {\ttfamily layer\+\_\+param\+\_\+}. Setting up the shapes of top blobs and internal buffers should be done in {\ttfamily Reshape}, which will be called before the forward pass to adjust the top blob sizes. 

Reimplemented from \hyperlink{classcaffe_1_1Layer_a38dc2488bf319b8de5a7ac84e0045393}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!caffe\+::\+Swish\+Layer@{caffe\+::\+Swish\+Layer}}
\subsubsection[{\texorpdfstring{Reshape(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{Reshape(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Swish\+Layer}$<$ Dtype $>$\+::Reshape (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}\hypertarget{classcaffe_1_1SwishLayer_a06173b1a0bdc7df0a21535a1fc0cf2a9}{}\label{classcaffe_1_1SwishLayer_a06173b1a0bdc7df0a21535a1fc0cf2a9}


Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the input blobs, with the requested input shapes \\
\hline
{\em top} & the top blobs, which should be reshaped as needed\\
\hline
\end{DoxyParams}
This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. 

Reimplemented from \hyperlink{classcaffe_1_1NeuronLayer_a810f5f75b95ba7fdcb9d3e0e33e98a7e}{caffe\+::\+Neuron\+Layer$<$ Dtype $>$}.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
include/caffe/layers/swish\+\_\+layer.\+hpp\item 
src/caffe/layers/swish\+\_\+layer.\+cpp\end{DoxyCompactItemize}
