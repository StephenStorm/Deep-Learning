\hypertarget{classcaffe_1_1LogLayer}{}\section{caffe\+:\+:Log\+Layer$<$ Dtype $>$ Class Template Reference}
\label{classcaffe_1_1LogLayer}\index{caffe\+::\+Log\+Layer$<$ Dtype $>$@{caffe\+::\+Log\+Layer$<$ Dtype $>$}}


Computes $ y = log_{\gamma}(\alpha x + \beta) $, as specified by the scale $ \alpha $, shift $ \beta $, and base $ \gamma $.  




{\ttfamily \#include $<$log\+\_\+layer.\+hpp$>$}

Inheritance diagram for caffe\+:\+:Log\+Layer$<$ Dtype $>$\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=3.000000cm]{classcaffe_1_1LogLayer}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classcaffe_1_1LogLayer_aa6f92a0b12140d70a44a2bcb71bab552}{Log\+Layer} (const Layer\+Parameter \&param)
\item 
virtual void \hyperlink{classcaffe_1_1LogLayer_ab3f8854a38095f499e44ad8edf15b97b}{Layer\+Set\+Up} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\begin{DoxyCompactList}\small\item\em Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. \end{DoxyCompactList}\item 
virtual const char $\ast$ \hyperlink{classcaffe_1_1LogLayer_a35fe9f30bc494fb930aa0c7a19dadace}{type} () const \hypertarget{classcaffe_1_1LogLayer_a35fe9f30bc494fb930aa0c7a19dadace}{}\label{classcaffe_1_1LogLayer_a35fe9f30bc494fb930aa0c7a19dadace}

\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \hyperlink{classcaffe_1_1LogLayer_a928ac703824992b46eb33210e049fdb6}{Forward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\item 
virtual void \hyperlink{classcaffe_1_1LogLayer_a6f9540e08387ce74287a6ee7abca8b1c}{Forward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)\hypertarget{classcaffe_1_1LogLayer_a6f9540e08387ce74287a6ee7abca8b1c}{}\label{classcaffe_1_1LogLayer_a6f9540e08387ce74287a6ee7abca8b1c}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the layer output. Fall back to \hyperlink{classcaffe_1_1LogLayer_a928ac703824992b46eb33210e049fdb6}{Forward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1LogLayer_adde7e59f9b065e518e6f254c408eb3ef}{Backward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the error gradient w.\+r.\+t. the exp inputs. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1LogLayer_ac4399854936b71196392d7736c162081}{Backward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)\hypertarget{classcaffe_1_1LogLayer_ac4399854936b71196392d7736c162081}{}\label{classcaffe_1_1LogLayer_ac4399854936b71196392d7736c162081}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. Fall back to \hyperlink{classcaffe_1_1LogLayer_adde7e59f9b065e518e6f254c408eb3ef}{Backward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
Dtype {\bfseries base\+\_\+scale\+\_\+}\hypertarget{classcaffe_1_1LogLayer_a491b3c774d06e7444e098f5e92116473}{}\label{classcaffe_1_1LogLayer_a491b3c774d06e7444e098f5e92116473}

\item 
Dtype {\bfseries input\+\_\+scale\+\_\+}\hypertarget{classcaffe_1_1LogLayer_a8c45b84ac085d9422655e68c107aa38f}{}\label{classcaffe_1_1LogLayer_a8c45b84ac085d9422655e68c107aa38f}

\item 
Dtype {\bfseries input\+\_\+shift\+\_\+}\hypertarget{classcaffe_1_1LogLayer_aea8ff4c75c4d1332801b91af479916af}{}\label{classcaffe_1_1LogLayer_aea8ff4c75c4d1332801b91af479916af}

\item 
Dtype {\bfseries backward\+\_\+num\+\_\+scale\+\_\+}\hypertarget{classcaffe_1_1LogLayer_ab87303089b3708884efaabef8a5e0df2}{}\label{classcaffe_1_1LogLayer_ab87303089b3708884efaabef8a5e0df2}

\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Dtype$>$\\*
class caffe\+::\+Log\+Layer$<$ Dtype $>$}

Computes $ y = log_{\gamma}(\alpha x + \beta) $, as specified by the scale $ \alpha $, shift $ \beta $, and base $ \gamma $. 

\subsection{Constructor \& Destructor Documentation}
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Log\+Layer@{Log\+Layer}}
\index{Log\+Layer@{Log\+Layer}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection[{\texorpdfstring{Log\+Layer(const Layer\+Parameter \&param)}{LogLayer(const LayerParameter &param)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ {\bf caffe\+::\+Log\+Layer}$<$ Dtype $>$\+::{\bf Log\+Layer} (
\begin{DoxyParamCaption}
\item[{const Layer\+Parameter \&}]{param}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}\hypertarget{classcaffe_1_1LogLayer_aa6f92a0b12140d70a44a2bcb71bab552}{}\label{classcaffe_1_1LogLayer_aa6f92a0b12140d70a44a2bcb71bab552}

\begin{DoxyParams}{Parameters}
{\em param} & provides Log\+Parameter log\+\_\+param, with \hyperlink{classcaffe_1_1LogLayer}{Log\+Layer} options\+:
\begin{DoxyItemize}
\item scale ({\bfseries optional}, default 1) the scale $ \alpha $
\item shift ({\bfseries optional}, default 0) the shift $ \beta $
\item base ({\bfseries optional}, default -\/1 for a value of $ e \approx 2.718 $) the base $ \gamma $ 
\end{DoxyItemize}\\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection[{\texorpdfstring{Backward\+\_\+cpu(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom)}{Backward_cpu(const vector< Blob< Dtype > * > &top, const vector< bool > &propagate_down, const vector< Blob< Dtype > * > &bottom)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Log\+Layer}$<$ Dtype $>$\+::Backward\+\_\+cpu (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top, }
\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1LogLayer_adde7e59f9b065e518e6f254c408eb3ef}{}\label{classcaffe_1_1LogLayer_adde7e59f9b065e518e6f254c408eb3ef}


Computes the error gradient w.\+r.\+t. the exp inputs. 


\begin{DoxyParams}{Parameters}
{\em top} & output \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ containing error gradients $ \frac{\partial E}{\partial y} $ with respect to computed outputs $ y $ 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \hyperlink{classcaffe_1_1Layer_a53df1e081767e07bfb4c81657f4acd0a}{Layer\+::\+Backward}. \\
\hline
{\em bottom} & input \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $; Backward fills their diff with gradients $ \frac{\partial E}{\partial x} = \frac{\partial E}{\partial y} y \alpha \log_e(gamma) $ if propagate\+\_\+down\mbox{[}0\mbox{]} 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \hyperlink{classcaffe_1_1Layer_a64d15855f882af4b82e83fa993c4e7c6}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection[{\texorpdfstring{Forward\+\_\+cpu(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{Forward_cpu(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Log\+Layer}$<$ Dtype $>$\+::Forward\+\_\+cpu (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1LogLayer_a928ac703824992b46eb33210e049fdb6}{}\label{classcaffe_1_1LogLayer_a928ac703824992b46eb33210e049fdb6}

\begin{DoxyParams}{Parameters}
{\em bottom} & input \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $ 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \hyperlink{classcaffe_1_1Blob}{Blob} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the computed outputs $ y = log_{\gamma}(\alpha x + \beta) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \hyperlink{classcaffe_1_1Layer_add965883f75bbf90c7a06f960cda7a1a}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Layer\+Set\+Up@{Layer\+Set\+Up}}
\index{Layer\+Set\+Up@{Layer\+Set\+Up}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection[{\texorpdfstring{Layer\+Set\+Up(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{LayerSetUp(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Log\+Layer}$<$ Dtype $>$\+::Layer\+Set\+Up (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}\hypertarget{classcaffe_1_1LogLayer_ab3f8854a38095f499e44ad8edf15b97b}{}\label{classcaffe_1_1LogLayer_ab3f8854a38095f499e44ad8edf15b97b}


Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the preshaped input blobs, whose data fields store the input data for this layer \\
\hline
{\em top} & the allocated but unshaped output blobs\\
\hline
\end{DoxyParams}
This method should do one-\/time layer specific setup. This includes reading and processing relevent parameters from the {\ttfamily layer\+\_\+param\+\_\+}. Setting up the shapes of top blobs and internal buffers should be done in {\ttfamily Reshape}, which will be called before the forward pass to adjust the top blob sizes. 

Reimplemented from \hyperlink{classcaffe_1_1Layer_a38dc2488bf319b8de5a7ac84e0045393}{caffe\+::\+Layer$<$ Dtype $>$}.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
include/caffe/layers/log\+\_\+layer.\+hpp\item 
src/caffe/layers/log\+\_\+layer.\+cpp\end{DoxyCompactItemize}
