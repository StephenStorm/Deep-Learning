\hypertarget{classcaffe_1_1BatchNormLayer}{}\section{caffe\+:\+:Batch\+Norm\+Layer$<$ Dtype $>$ Class Template Reference}
\label{classcaffe_1_1BatchNormLayer}\index{caffe\+::\+Batch\+Norm\+Layer$<$ Dtype $>$@{caffe\+::\+Batch\+Norm\+Layer$<$ Dtype $>$}}


Normalizes the input to have 0-\/mean and/or unit (1) variance across the batch.  




{\ttfamily \#include $<$batch\+\_\+norm\+\_\+layer.\+hpp$>$}

Inheritance diagram for caffe\+:\+:Batch\+Norm\+Layer$<$ Dtype $>$\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classcaffe_1_1BatchNormLayer}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
{\bfseries Batch\+Norm\+Layer} (const Layer\+Parameter \&param)\hypertarget{classcaffe_1_1BatchNormLayer_add0e20ed67cad3052669765cda52a7f0}{}\label{classcaffe_1_1BatchNormLayer_add0e20ed67cad3052669765cda52a7f0}

\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_ae4784dc3c124ea934b1d9736d465591f}{Layer\+Set\+Up} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\begin{DoxyCompactList}\small\item\em Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_afb4c4da26887dfbd6d73ab35be17ed84}{Reshape} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)
\begin{DoxyCompactList}\small\item\em Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. \end{DoxyCompactList}\item 
virtual const char $\ast$ \hyperlink{classcaffe_1_1BatchNormLayer_acf78346b46fa24e33337db9e155e4001}{type} () const \hypertarget{classcaffe_1_1BatchNormLayer_acf78346b46fa24e33337db9e155e4001}{}\label{classcaffe_1_1BatchNormLayer_acf78346b46fa24e33337db9e155e4001}

\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\item 
virtual int \hyperlink{classcaffe_1_1BatchNormLayer_a30b42ad6c976170fc0a8c523682ff96a}{Exact\+Num\+Bottom\+Blobs} () const 
\begin{DoxyCompactList}\small\item\em Returns the exact number of bottom blobs required by the layer, or -\/1 if no exact number is required. \end{DoxyCompactList}\item 
virtual int \hyperlink{classcaffe_1_1BatchNormLayer_ad9fb4bf90a79a0a739ed1223628a88b9}{Exact\+Num\+Top\+Blobs} () const 
\begin{DoxyCompactList}\small\item\em Returns the exact number of top blobs required by the layer, or -\/1 if no exact number is required. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_a93fc10c42a94d9bf61fb10b73521b23b}{Forward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)\hypertarget{classcaffe_1_1BatchNormLayer_a93fc10c42a94d9bf61fb10b73521b23b}{}\label{classcaffe_1_1BatchNormLayer_a93fc10c42a94d9bf61fb10b73521b23b}

\begin{DoxyCompactList}\small\item\em Using the C\+PU device, compute the layer output. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_ae5832f8ba488345842129c99e743cfe6}{Forward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top)\hypertarget{classcaffe_1_1BatchNormLayer_ae5832f8ba488345842129c99e743cfe6}{}\label{classcaffe_1_1BatchNormLayer_ae5832f8ba488345842129c99e743cfe6}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the layer output. Fall back to \hyperlink{classcaffe_1_1BatchNormLayer_a93fc10c42a94d9bf61fb10b73521b23b}{Forward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_ac3dd99d7fc010d3a2567034c50324b60}{Backward\+\_\+cpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)\hypertarget{classcaffe_1_1BatchNormLayer_ac3dd99d7fc010d3a2567034c50324b60}{}\label{classcaffe_1_1BatchNormLayer_ac3dd99d7fc010d3a2567034c50324b60}

\begin{DoxyCompactList}\small\item\em Using the C\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. \end{DoxyCompactList}\item 
virtual void \hyperlink{classcaffe_1_1BatchNormLayer_a4e3c00252a8f4b7891ca2b43f14bcdfb}{Backward\+\_\+gpu} (const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ $\ast$ $>$ \&bottom)\hypertarget{classcaffe_1_1BatchNormLayer_a4e3c00252a8f4b7891ca2b43f14bcdfb}{}\label{classcaffe_1_1BatchNormLayer_a4e3c00252a8f4b7891ca2b43f14bcdfb}

\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. Fall back to \hyperlink{classcaffe_1_1BatchNormLayer_ac3dd99d7fc010d3a2567034c50324b60}{Backward\+\_\+cpu()} if unavailable. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries mean\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a40bdb2eb1eb8c1af257d83d1ee34477e}{}\label{classcaffe_1_1BatchNormLayer_a40bdb2eb1eb8c1af257d83d1ee34477e}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries variance\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a60af867dc745b550056fdb0bf5253fb2}{}\label{classcaffe_1_1BatchNormLayer_a60af867dc745b550056fdb0bf5253fb2}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries temp\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a385f18e414274c8398d7f68f7a21fd47}{}\label{classcaffe_1_1BatchNormLayer_a385f18e414274c8398d7f68f7a21fd47}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries x\+\_\+norm\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_ae6ff1b957b514a954dcb62ea5464d3eb}{}\label{classcaffe_1_1BatchNormLayer_ae6ff1b957b514a954dcb62ea5464d3eb}

\item 
bool {\bfseries use\+\_\+global\+\_\+stats\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_ad3a29633c4b31c90bc8524f271279deb}{}\label{classcaffe_1_1BatchNormLayer_ad3a29633c4b31c90bc8524f271279deb}

\item 
Dtype {\bfseries moving\+\_\+average\+\_\+fraction\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a080385766fcb5df87d46e5ce9ed6168e}{}\label{classcaffe_1_1BatchNormLayer_a080385766fcb5df87d46e5ce9ed6168e}

\item 
int {\bfseries channels\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_aceaba0d4877aefb36a320c9a147a613c}{}\label{classcaffe_1_1BatchNormLayer_aceaba0d4877aefb36a320c9a147a613c}

\item 
Dtype {\bfseries eps\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a578bf09a12d0ad6b6fb51600a1a1feb6}{}\label{classcaffe_1_1BatchNormLayer_a578bf09a12d0ad6b6fb51600a1a1feb6}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries batch\+\_\+sum\+\_\+multiplier\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a04b912c9e47737b4c91bf97bfd34c9ae}{}\label{classcaffe_1_1BatchNormLayer_a04b912c9e47737b4c91bf97bfd34c9ae}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries num\+\_\+by\+\_\+chans\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a18b26f0942f10d4de8562aca9c68e38d}{}\label{classcaffe_1_1BatchNormLayer_a18b26f0942f10d4de8562aca9c68e38d}

\item 
\hyperlink{classcaffe_1_1Blob}{Blob}$<$ Dtype $>$ {\bfseries spatial\+\_\+sum\+\_\+multiplier\+\_\+}\hypertarget{classcaffe_1_1BatchNormLayer_a1649265a7921b2fee4e99dd26069e74a}{}\label{classcaffe_1_1BatchNormLayer_a1649265a7921b2fee4e99dd26069e74a}

\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Dtype$>$\\*
class caffe\+::\+Batch\+Norm\+Layer$<$ Dtype $>$}

Normalizes the input to have 0-\/mean and/or unit (1) variance across the batch. 

This layer computes \hyperlink{classcaffe_1_1Batch}{Batch} Normalization as described in \mbox{[}1\mbox{]}. For each channel in the data (i.\+e. axis 1), it subtracts the mean and divides by the variance, where both statistics are computed across both spatial dimensions and across the different examples in the batch.

By default, during training time, the network is computing global mean/variance statistics via a running average, which is then used at test time to allow deterministic outputs for each input. You can manually toggle whether the network is accumulating or using the statistics via the use\+\_\+global\+\_\+stats option. For reference, these statistics are kept in the layer\textquotesingle{}s three blobs\+: (0) mean, (1) variance, and (2) moving average factor.

Note that the original paper also included a per-\/channel learned bias and scaling factor. To implement this in \hyperlink{classcaffe_1_1Caffe}{Caffe}, define a {\ttfamily \hyperlink{classcaffe_1_1ScaleLayer}{Scale\+Layer}} configured with {\ttfamily bias\+\_\+term\+: true} after each {\ttfamily \hyperlink{classcaffe_1_1BatchNormLayer}{Batch\+Norm\+Layer}} to handle both the bias and scaling factor.

\mbox{[}1\mbox{]} S. Ioffe and C. Szegedy, \char`\"{}\+Batch Normalization\+: Accelerating Deep Network
    Training by Reducing Internal Covariate Shift.\char`\"{} ar\+Xiv preprint ar\+Xiv\+:1502.\+03167 (2015).

T\+O\+D\+O(dox)\+: thorough documentation for Forward, Backward, and proto params. 

\subsection{Member Function Documentation}
\index{caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}!Exact\+Num\+Bottom\+Blobs@{Exact\+Num\+Bottom\+Blobs}}
\index{Exact\+Num\+Bottom\+Blobs@{Exact\+Num\+Bottom\+Blobs}!caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}}
\subsubsection[{\texorpdfstring{Exact\+Num\+Bottom\+Blobs() const }{ExactNumBottomBlobs() const }}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ virtual int {\bf caffe\+::\+Batch\+Norm\+Layer}$<$ Dtype $>$\+::Exact\+Num\+Bottom\+Blobs (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1BatchNormLayer_a30b42ad6c976170fc0a8c523682ff96a}{}\label{classcaffe_1_1BatchNormLayer_a30b42ad6c976170fc0a8c523682ff96a}


Returns the exact number of bottom blobs required by the layer, or -\/1 if no exact number is required. 

This method should be overridden to return a non-\/negative value if your layer expects some exact number of bottom blobs. 

Reimplemented from \hyperlink{classcaffe_1_1Layer_a45c7a7943a8a6735ac433c9be11e0240}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}!Exact\+Num\+Top\+Blobs@{Exact\+Num\+Top\+Blobs}}
\index{Exact\+Num\+Top\+Blobs@{Exact\+Num\+Top\+Blobs}!caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}}
\subsubsection[{\texorpdfstring{Exact\+Num\+Top\+Blobs() const }{ExactNumTopBlobs() const }}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ virtual int {\bf caffe\+::\+Batch\+Norm\+Layer}$<$ Dtype $>$\+::Exact\+Num\+Top\+Blobs (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}\hypertarget{classcaffe_1_1BatchNormLayer_ad9fb4bf90a79a0a739ed1223628a88b9}{}\label{classcaffe_1_1BatchNormLayer_ad9fb4bf90a79a0a739ed1223628a88b9}


Returns the exact number of top blobs required by the layer, or -\/1 if no exact number is required. 

This method should be overridden to return a non-\/negative value if your layer expects some exact number of top blobs. 

Reimplemented from \hyperlink{classcaffe_1_1Layer_aa3c99ed707e8db683a3043412e151af8}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}!Layer\+Set\+Up@{Layer\+Set\+Up}}
\index{Layer\+Set\+Up@{Layer\+Set\+Up}!caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}}
\subsubsection[{\texorpdfstring{Layer\+Set\+Up(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{LayerSetUp(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Batch\+Norm\+Layer}$<$ Dtype $>$\+::Layer\+Set\+Up (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}\hypertarget{classcaffe_1_1BatchNormLayer_ae4784dc3c124ea934b1d9736d465591f}{}\label{classcaffe_1_1BatchNormLayer_ae4784dc3c124ea934b1d9736d465591f}


Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the preshaped input blobs, whose data fields store the input data for this layer \\
\hline
{\em top} & the allocated but unshaped output blobs\\
\hline
\end{DoxyParams}
This method should do one-\/time layer specific setup. This includes reading and processing relevent parameters from the {\ttfamily layer\+\_\+param\+\_\+}. Setting up the shapes of top blobs and internal buffers should be done in {\ttfamily Reshape}, which will be called before the forward pass to adjust the top blob sizes. 

Reimplemented from \hyperlink{classcaffe_1_1Layer_a38dc2488bf319b8de5a7ac84e0045393}{caffe\+::\+Layer$<$ Dtype $>$}.

\index{caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!caffe\+::\+Batch\+Norm\+Layer@{caffe\+::\+Batch\+Norm\+Layer}}
\subsubsection[{\texorpdfstring{Reshape(const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&bottom, const vector$<$ Blob$<$ Dtype $>$ $\ast$ $>$ \&top)}{Reshape(const vector< Blob< Dtype > * > &bottom, const vector< Blob< Dtype > * > &top)}}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Dtype $>$ void {\bf caffe\+::\+Batch\+Norm\+Layer}$<$ Dtype $>$\+::Reshape (
\begin{DoxyParamCaption}
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{bottom, }
\item[{const vector$<$ {\bf Blob}$<$ Dtype $>$ $\ast$ $>$ \&}]{top}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}\hypertarget{classcaffe_1_1BatchNormLayer_afb4c4da26887dfbd6d73ab35be17ed84}{}\label{classcaffe_1_1BatchNormLayer_afb4c4da26887dfbd6d73ab35be17ed84}


Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the input blobs, with the requested input shapes \\
\hline
{\em top} & the top blobs, which should be reshaped as needed\\
\hline
\end{DoxyParams}
This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. 

Implements \hyperlink{classcaffe_1_1Layer_ad9d391b972c769c0ebee34ca6d1c973e}{caffe\+::\+Layer$<$ Dtype $>$}.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
include/caffe/layers/batch\+\_\+norm\+\_\+layer.\+hpp\item 
src/caffe/layers/batch\+\_\+norm\+\_\+layer.\+cpp\end{DoxyCompactItemize}
